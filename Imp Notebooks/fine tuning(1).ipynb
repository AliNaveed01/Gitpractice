{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import load model and save model\n",
    "from tensorflow.keras.models import load_model, save_model, model_from_json, model_from_yaml\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pictures from clothes folder\n",
    "clothes_folder = os.path.join(\"./clothes/\")\n",
    "# list the files in the folder\n",
    "clothes_files = os.listdir(clothes_folder)\n",
    "# print the list of files\n",
    "print(clothes_files)\n",
    "\n",
    "# load the pictures from clothes folder\n",
    "modelsfolder = os.path.join(\"./models\")\n",
    "# list the files in the folder\n",
    "modelsfiles = os.listdir(modelsfolder)\n",
    "# print the list of files\n",
    "#print(modelsfiles)\n",
    "\n",
    "\n",
    "# load the pictures from clothes folder\n",
    "trashfolder = os.path.join(\"./TrashPics\")\n",
    "# list the files in the folder\n",
    "trashfiles = os.listdir(trashfolder)\n",
    "# print the list of files\n",
    "#print(trashfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now store the images in a list, their paths in a list and assign them label 0\n",
    "images = []\n",
    "images_path = []\n",
    "labels = []\n",
    "for file in clothes_files:\n",
    "    images_path.append(os.path.join(clothes_folder, file))\n",
    "    images.append(tf.keras.preprocessing.image.load_img(os.path.join(clothes_folder, file), target_size=(227, 227)))\n",
    "    labels.append(0)\n",
    "\n",
    "\n",
    "for file in modelsfiles:\n",
    "    images_path.append(os.path.join(modelsfolder, file))\n",
    "    images.append(tf.keras.preprocessing.image.load_img(os.path.join(modelsfolder, file), target_size=(227, 227)))\n",
    "    labels.append(1)\n",
    "    \n",
    "    \n",
    "for file in trashfiles:\n",
    "    images_path.append(os.path.join(trashfolder, file))\n",
    "    images.append(tf.keras.preprocessing.image.load_img(os.path.join(trashfolder, file), target_size=(227, 227)))\n",
    "    labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv using these lists \n",
    "import pandas as pd \n",
    "data = {'Images': images, 'Labels': labels, 'Images Path': images_path}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('images.csv', index=False)\n",
    "# now load the csv\n",
    "df = pd.read_csv('images.csv')\n",
    "# print the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset \n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "# print the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will load the model best.keras \n",
    "model = load_model(\"./best.keras\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will train this model again on our dataset\n",
    "# first we will split the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# given the image, we have to predict the label\n",
    "X = df['Images Path']\n",
    "y = df['Labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# print the shape of the train and test sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will create a data generator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create a data generator\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "# create a train generator\n",
    "train_generator = datagen.flow_from_dataframe(df, x_col='Images Path', y_col='Labels', subset='training', target_size=(227, 227), class_mode='raw')\n",
    "# create a validation generator\n",
    "val_generator = datagen.flow_from_dataframe(df, x_col='Images Path', y_col='Labels', subset='validation', target_size=(227, 227), class_mode='raw')\n",
    "# now we will train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a picture and test it \n",
    "pic = cv2.imread('hello.jpg')\n",
    "pic = cv2.cvtColor(pic, cv2.COLOR_BGR2RGB)\n",
    "pic = cv2.resize(pic, (227, 227))\n",
    "pic = np.array(pic)\n",
    "pic = np.expand_dims(pic, axis=0)\n",
    "#print(pic)\n",
    "\n",
    "# now we will predict the class of the image\n",
    "prediction = model.predict(pic)\n",
    "print(prediction)\n",
    "# get the class with the highest probability\n",
    "print(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model and history \n",
    "model.save('finetuned.keras')\n",
    "import pickle\n",
    "with open('history.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
